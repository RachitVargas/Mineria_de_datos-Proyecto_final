---
title: "Mineria de datos - Proyecto Final "
author: "Verónica Ferreto, Kevin Gamboa, Melissa Pérez y Rachit Vargas"
date: "11/28/2021"
output: rmdformats::readthedown
---

# Librerías

```{r message=FALSE}
library(tidyverse)
library(rmdformats)
library(stats)
library(cluster)
library(mclust)
library(factoextra)
library(dendextend)
library(DT)
library(purrr)
library(igraph)
library(tidygraph)
library(ggraph)
library(ggpubr)
library(clustertend)
library(fpc)
library(FactoMineR)
library(factoextra)
library(pvclust)
library(cluster.datasets)
library(mltools)
library(data.table)
library(corrplot)
```


# Datos

```{r message=FALSE}

file <- "/Users/antony.vargasulead.ac.cr/Mineria de datos/Proyecto Final/Data/Heart.csv"
df <- read.csv(file, sep = ",", dec = ".")
df <- df[,!(names(df) %in% "target")]
DT::datatable(df)

```



## 2. Análisis descriptivo

### 2.1 Datos cualitativos

```{r}

df_cualitativo <- df[, c("age", "trestbps", "chol", "thalach", "oldpeak")]
head(df_cualitativo)

```

### 2.2 Resumen

```{r}

print("Resumen estadistico")
summary(df_cualitativo)

```


### 2.3 Desviaciones estándar

```{r}

for (i in colnames(df_cualitativo)){
  print(i)
  print((sd(df[, i])))
}

```

### 2.4 Cuartiles en diagrama de cajas

1. boxplot() es una función que nos ayuda a crear un gráfico caja o una caja de bigotes. 

2. Además, representa gráficamente una serie de datos numéricos a través de sus cuartiles. De esta manera, el diagrama de caja muestra a simple vista la mediana y los cuartiles de los datos. También puede representar los valores atípicos de estos.


```{r}
par(mfrow=c(2,3))

boxplot(df_cualitativo$age,
        main = "Boxplot - Age",
        ylab = "Age",
        col = "orange",
        border = "brown",
        horizontal = FALSE,
        notch = TRUE)

boxplot(df_cualitativo$trestbps,
        main = "Boxplot - Trestbps",
        ylab = "Trestbps",
        col = "orange",
        border = "brown",
        horizontal = FALSE,
        notch = TRUE)

boxplot(df_cualitativo$chol,
        main = "Boxplot - Chol",
        ylab = "Chol",
        col = "orange",
        border = "brown",
        horizontal = FALSE,
        notch = TRUE)


boxplot(df_cualitativo$thalach,
        main = "Boxplot - Thalach",
        ylab = "thalach",
        col = "orange",
        border = "brown",
        horizontal = FALSE,
        notch = TRUE)

boxplot(df_cualitativo$oldpeak,
        main = "Boxplot - Oldpeak",
        ylab = "Oldpeak",
        col = "orange",
        border = "brown",
        horizontal = FALSE,
        notch = TRUE)

```

### 2.5 Diagramas de frecuencia

```{r}
par(mfrow=c(2,3))

hist(x = df_cualitativo$age, main = "Histograma de Edad", 
     xlab = "Edad", ylab = "Frecuencia",
     col = "purple")

hist(x = df_cualitativo$trestbps, main = "Histograma de Presión arterial", 
     xlab = "Presión arterial", ylab = "Frecuencia",
     col = "purple")

hist(x = df_cualitativo$chol, main = "Histograma de Colesterol", 
     xlab = "Colesterol", ylab = "Frecuencia",
     col = "purple")

hist(x = df_cualitativo$thalach, main = "Histograma de Cardíaca máxima", 
     xlab = "Cardíaca máxima", ylab = "Frecuencia",
     col = "purple")

hist(x = df_cualitativo$oldpeak, main = "Histograma de Depresión del ST", 
     xlab = "Depresión del ST", ylab = "Frecuencia",
     col = "purple")
```

### 2.6 Relación entre las variables y sus correlaciones

Análisis de correlación de variables 

Introducción 
La correlación es un tipo de asociación entre dos variables numéricas, específicamente evalúa la tendencia (creciente o decreciente) en los datos.

El signo nos indica la dirección de la relación, como hemos visto en el diagrama de dispersión. Un valor positivo indica una relación, directa o positiva, un valor negativo indica relación indirecta, inversa o negativa,un valor nulo indica que no existe una tendencia entre ambas variables (puede ocurrir que no exista relación o que la relación sea más compleja que una tendencia, por ejemplo, una relación en forma de U).


2. Correlación gráfica entre todas las variables:

La función pairs nos permite cruzar todas las variables del dataset a modo de tabla donde el eje x de una gráfica corresponde a la columna donde se encuentra y el eje y a la fila.

Cuando vemos que los puntos parecen ir de manera descendente, nos indica que hay una correlación negativa, cuando parecen ir de manera ascendente, esto nos indica una correlación positiva.  

```{r, message=FALSE}
library("ggplot2")
library("GGally")
ggpairs(df_cualitativo)
```

### 2.7 Correlaciones entre las variables

```{r}

correlacion <- cor(df_cualitativo)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(correlacion, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black",
         tl.col="black", tl.srt=45,
         diag=FALSE)

```


## 3. Análisis no Supervisado:

### 3.1 Análisis de componentes principales

```{r}

PCA <- PCA(df, graph = FALSE, dim(df)[2])
PCA

```

#### 3.1.1 Tabla general

```{r}
eig.tmp <- PCA$eig

eig.tmp[,2:3]<-eig.tmp[,2:3]/100.

DT::datatable(eig.tmp) %>% 
  formatRound('eigenvalue',2) %>% 
  formatPercentage(c('percentage of variance','cumulative percentage of variance'),2)

```
### 3.1.2 Gráfico de sedimentación

```{r}

ggplot(data = data.frame(prop_varianza_acum = PCA$eig[,3], pc = 1:dim(PCA$eig)[1]),
       aes(x = pc, y = prop_varianza_acum, group = 1)) +
  geom_point() +
  geom_line() +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Prop. varianza explicada acumulada")

```

### 3.1.3 Tabla de cosenos cuadrados - individuos

```{r}

DT::datatable(PCA$ind$cos2) %>%
  formatPercentage(colnames(PCA$ind$cos2),2)

```
### 3.1.4 Tabla de contribuciones - individuos

```{r}

DT::datatable(PCA$ind$contrib) %>% 
  formatRound(colnames(PCA$ind$contrib),3)

```


### 3.1.5 Tabla de cosenos cuadrados - variables

```{r}

DT::datatable(PCA$var$cos2) %>% 
  formatPercentage(colnames(PCA$var$cos2),2)

```

### 3.1.6 Tabla de contribuciones - variables

```{r}

DT::datatable(PCA$var$contrib) %>% 
  formatRound(colnames(PCA$var$contrib),3)

```

### 3.1.7 Plano principal - Cosenos cuadrados de individuos

```{r}

fviz_pca_ind(PCA, col.ind="cos2", select.ind = list(cos2 = 0.60), geom = "point",
   gradient.cols = c("black", "#2E9FDF", "#FC4E07" ), title  = "Cosenos cuadrados - individuos")

```


### 3.1.8 Plano principal - Contribución de individuos

```{r}

fviz_pca_ind(PCA, col.ind="contrib", geom = "point",
   gradient.cols = c("black", "#2E9FDF", "#FC4E07" ), title  = "Ejemplo 1 Contribución",repel = TRUE)

```



### 3.1.9 Cículo de correlación - Cosenos cuadrados individuos

```{r}

fviz_pca_var(PCA, col.var = "cos2",
   gradient.cols = c("black", "blue", "red"),
   ggtheme = theme_minimal())

```

### 3.1.10 Cículo de correlación - Contribución individuos

```{r}

fviz_pca_var(PCA, col.var = "contrib",
   gradient.cols = c("black", "blue", "red"),
   ggtheme = theme_minimal())

```
### 3.1.11 Correlación entre variables originales y los componentes principales

```{r}

library(corrplot)
corrplot(PCA$var$cor)

```


## 3.2 Análisis de correspondencia simple 

### 3.2.1 Aplicación del Análisis de correspondencia simple (ACS)

```{r}

ACS <- CA(df, graph = TRUE, dim(df)[2])

```


### 3.2.2 Valores propios - inercia explicada

```{r}

fviz_eig(ACS, linecolor = "#FC4E07", 
         barcolor = "#00AFBB", barfill = "#00AFBB")

```

### 3.2.3 Plano principal - Cosenos cuadrados de individuos

```{r}

fviz_ca_row(ACS, select.row = list(cos2 = 0.60), col.row = "cos2", geom = "point",
            gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
            repel = TRUE)

```

### 3.2.4 Plano principal - Cosenos cuadrado de variables

```{r}

fviz_ca_col(ACS, col.col = "cos2", 
            gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))

```

### 3.2.4 Gráfico de sobreposición

```{r}

fviz_ca_biplot(ACS, select.row = list(cos2 = 0.80), repel = TRUE)

```

## 3.4 Sentido de la clusterización en el problema

```{r}
set.seed(321)
df_scale <- scale(df, center = TRUE, scale = TRUE)

hopkins(data = df_scale, n = nrow(df_scale) - 1)
```

No tiene mucho sentido la clusterización de este problema, ya que el índice de Hopkins da un resultado de 32.3%, superior al 25%, el cual indica que no tiene mucho sentido realizar la clusterización. Un resultado cercano al 50% indica que del todo no se puede clusterizar y el índice se hacer a ese porcentaje


## 3.5 Clusterización

### 3.5.1 Kmeans

```{r}

km.datos <- kmeans(x = df_scale, centers = 5)

p1 <- fviz_cluster(object = km.datos, data = df_scale,
                   ellipse.type = "norm", geom = "point", main = "Datos iris",
                   stand = FALSE, palette = "jco") +
  theme_bw() + theme(legend.position = "none")

p1

```

### 3.5.2 Clustering jerárquico

```{r}

hc <- hclust(d = dist(x = df_scale, method = "euclidean"),
                               method = "complete")

fviz_dend(x = hc, k = 5, cex = 0.6) +
  labs(title = "Herarchical clustering",
       subtitle = "Distancia euclídea, Lincage complete, K=2")

```

## 3.6 Número óptimo de k clúster

```{r}

jambu <- fviz_nbclust(x = df_scale, FUNcluster = kmeans, method = "wss", k.max = 15, 
             diss = get_dist(df_scale, method = "euclidean"), nstart = 50)

jambu

```

Es difícil determinar la cantidad k óptima de clúster, ya que en el Codo de Jambú se nota que la línea no se lográ estabilizarse, sin embargo a criterio, podemos determinar que el mejor número es k = 5, sin embargo no se sabe con certeza.


## 3.7 Indicadores para la evaluación de los clústeres

### 3.7.1 Visual Assessment of cluster Tendency (VAT)

```{r}

dist_data <- dist(df_scale, method = "euclidean")

p2 <- fviz_dist(dist.obj = dist_data, show_labels = FALSE) +
      labs(title = "Datos - Heart") + theme(legend.position = "bottom")

p2
```




